# depth_v1
########################################################################################################################
写在最前面：
该项目为天津大学大创选拔院级立项，代码最终解释权归本作者所有
感谢你花时间来看几个本科生在大一的时候的幼稚构想，我们自己没有跑过这个程序哦，要是有好心人帮我们跑了模型，请一定要告诉作者效果如何哦
作者：烤馒头爱吃凉的啦(kaomento)
########################################################################################################################
本工作通过对两个技术进行结合，提出了一种时空联合动态剪枝策略，用FLOWNE（神经光流网络）提取运动区域，并通过进化算法（CMA-ES），动态优化剪枝策略，使之兼顾精度与效率。此外，依靠引入类脑脉冲恢复机制，模拟生物神经系统的脉冲触发特性，这项机制可以在模型识别到关键特征（如危险因素等）时激活，作为保护机制，以提升模型对突发状况的响应和适应能力。 综上，本项目旨在开发一种适用于动态环境的高效视觉感知系统，通过结合进化算法与动态剪枝技术，提升Transformer模型在自动驾驶、机器人导航等场景应用中的实时性和鲁棒性。我们将其命名为Dynamic Evolutionary Pruning Transformer（DEPTH）。

1.1研究背景
动态环境感知需求：自动驾驶、机器人导航等场景需实时处理动态物体（行人、车辆）、光照变化、遮挡等问题，传统语义分割模型（如CNN）在长距离依赖和计算效率上面临瓶颈。
Transformer的潜力与局限：Vision Transformer通过全局注意力提升分割精度，但计算复杂度高，数据处理速度较慢，难以满足动态场景实时性需求。
类脑智能的启发：生物神经系统通过突触可塑性和脉冲通信实现高效动态计算，为优化模型与提升系统适应性提供新思路。
1.2国内外研究基础
1．Transformer算法
Vision Transformer (ViT)1：由Dosovitskiy等人提出，首次将Transformer架构应用于图像分类任务，将图像分割为固定大小的图块（如16×16像素），每个图块线性映射为Token序列，输入标准Transformer Encoder进行全局关系建模,展示了其在处理长距离依赖关系方面的优势。
Swin Transformer2：由微软研究院提出，通过引入层次化和局部化的注意力机制，将图像划分为局部窗口（如7×7），窗口内计算自注意力，复杂度下降，显著提升了Vision Transformer在计算机视觉任务中的性能。
Dynamic-ViT3：由Liu等人提出，提出了一种动态Token稀疏化方法，在每层Transformer后插入轻量级MLP，预测每个Token的重要性得分；逐层丢弃低得分Token（如保留前50%），后续层仅处理保留的Token。通过在推理过程中动态裁剪冗余Token，显著降低了计算量。
2. 动态剪枝
Ada-ViT4：由Rao等人提出，提出了一种自适应剪枝方法，为每个Token引入可学习门控参数，通过Gumbel-Softmax实现端到端二值化决策。实现了在保持高精度的同时，显著降低计算量。
Dynamic Neural Networks5：麻省理工学院的研究团队提出了一系列动态神经网络方法，根据输入复杂度动态激活网络分支（如早期退出、动态深度）；在对象检测任务中，仅对包含目标的图像区域进行高精度推理。实现了高效的资源利用。
3. 进化算法
神经架构搜索(NAS)6：Google、Facebook等公司在神经架构搜索领域进行了大量研究，利用进化算法、贝叶斯优化等方法自动搜索最优的网络架构。
CMA-ES算法7：由Hansen等人提出，通过多元高斯分布建模搜索空间，动态调整均值和协方差矩阵。适用于高维非凸问题（如超参数优化、机器人控制），广泛应用于优化问题，包括神经网络参数优化和架构搜索。
4. 类脑计算
SNN (Spiking Neural Networks)8：由Maass等人提出，模拟生物神经系统的脉冲通信机制，信息通过脉冲时序（Spike Timing）表示，支持事件驱动计算。近年来在事件驱动感知和低功耗计算方面展现出巨大潜力。
Intel Loihi9：Intel推出的神经形态计算芯片，专为SNN设计，支持高效的脉冲计算和低功耗处理。
1.3研究意义
理论价值
	推动自适应AI模型的理论创新：提出动态结构与输入数据协同优化的新范式，突破传统静态模型的局限性，探索基于进化算法的动态剪枝机制，为动态环境感知建立可解释、可进化的模型架构理论。
	促进跨领域方法融合：将进化算法（优化理论）与动态剪枝（深度学习压缩技术）结合，发展新型混合优化框架（如多目标动态资源分配、在线模型压缩），丰富人工智能方法论体系。
	深化动态环境感知机理研究：通过动态剪枝保留的关键模块和进化策略生成的多样性网络分支，揭示模型在复杂场景下的注意力分配规律，增强模型行为可解释性。
应用价值
	提升复杂场景的感知性能：在自动驾驶、无人机避障等领域实现高鲁棒性视觉感知，解决动态遮挡、光照突变等干扰问题，保障实时性与安全性。
	突破计算效率瓶颈：通过动态剪枝降低Transformer的计算复杂度，适配边缘设备（如智能摄像头、移动机器人），推动高精度模型在低功耗场景的落地。
	推动绿色AI发展：减少冗余计算，降低模型推理能耗，支持智慧城市、物联网等大规模部署场景的可持续发展需求。
	拓展技术应用边界：为增强现实（AR）、开放环境机器人等新兴领域提供自适应感知解决方案，加速通用人工智能（AGI）技术演进。
2.研究目标 
1.提升动态环境下的模型效率
动态剪枝技术剪除注意力矩阵中不重要的块或头，将Transformer的计算复杂度降低到接近线性。 在处理长序列时，动态剪枝不重要的Token（如LazyLLM和动态Token剪枝技术），仅保留对当前预测关键的部分，减少KV缓存的计算需求。
2.优化模型架构的自适应能力
在剪枝过程中保持模型精度，通过进化策略筛选最优剪枝阈值或区域，使其能够根据实际环境自动优化网络结构（如注意力头数、层深度等），适应不同场景的感知需求。避免因过度剪枝导致关键信息丢失，实现效率与准确率的双优化。 
3.实现脉冲式特征恢复机制
该机制使模型在低功耗常态运行与高精度应急响应间灵活切换，在自动驾驶、安防监控等场景中，可在突发事件下将目标分割精度从剪枝后的状态快速恢复至剪枝前的状态，同时整体能耗仅小幅增加，显著优于传统固定剪枝方案。
3.项目特色创新概述
（注：由于缺乏实验所需的资源，以下出现的关于DEPTH的性能均为推测）
创新点一：进化算法驱动的自适应优化框架
传统方法局限性：
1.人工调参低效：依赖经验调整剪枝率、学习率等参数，对时间和算力消耗大，且难以获得全局最优解。
2.场景固化：固定参数无法适应不同环境（如白天/夜晚、城市公路/高速公路）。
我们的创新技术：
1.多目标进化优化：将剪枝率、运动阈值等参数编码为基因，通过CMA-ES算法10最大化“精度-效率”帕累托前沿（Pareto Frontier）。
2.持续学习机制：在部署后持续收集环境数据，定期进化更新模型参数，适应长期场景变化。
对比优势：
维度	传统方法（人工调参/固定参数）	DEPTH
参数优化效率	需数周人工实验，局部最优风险高	全自动搜索，24小时内找到全局最优解
跨场景泛化性	单一场景优化，极端环境性能骤降	自适应调整参数，暴雨/夜间场景精度波动减少 60%
长期部署适应性	模型性能随时间推移下降（遗忘问题）11	持续学习机制保障精度稳定性（遗忘率下降70%）
________________________________________
创新点二：时空联合动态剪枝技术
传统方法局限性：
	静态剪枝：训练后固定剪枝率，无法适应动态场景的变化。（如光照变化、突发情况等）
	空间冗余：传统方法（如Swin Transformer）仅通过固定窗口划分减少计算量，忽视视频流中的时间冗余（如静态背景跨帧重复计算）。
	人工调参依赖：剪枝阈值需手动设定，难以平衡精度与效率。
我们的创新技术：
	光流引导的动态稀疏化：利用光流网络实时区分动态区域与静态区域，仅在动态区域保留密集计算，静态区域降采样或复用历史特征。
	进化算法优化的动态剪枝策略：通过CMA-ES算法自动搜索最优剪枝率与运动检测阈值，替代人工调参，实现输入自适应。
对比优势：
维度	传统方法（如Swin-T、DynamicViT）	DEPTH
稀疏性依据	固定窗口或静态规则	光流运动分析 + 进化策略动态调整
计算效率	FLOPs降低20%-30%	FLOPs降低40%-50%
动态场景适应性	突发场景精度下降显著（mIoU下降3%-5%）	突发场景精度保持稳定（mIoU仅下降0.8%）
________________________________________
创新点三：脉冲式特征恢复机制
传统方法局限性：
	不可逆剪枝：传统剪枝（如通道剪枝Channel Pruning）永久移除计算单元，突发关键特征（如突然出现的行人）无法恢复，导致安全隐患。
	能量浪费：静态恢复机制（如定期全计算）在无突发事件时仍消耗资源。
我们的创新技术：
	类脑脉冲触发：模拟生物神经元“按需激活”特性，仅在检测到特征突变（梯度激增）时临时恢复被剪枝的注意力计算。
	能量约束机制：通过脉冲发放频率控制恢复时长，确保计算增量≤15%。
对比优势：
维度	传统方法（不可逆剪枝/全计算）	DEPTH
突发场景处理	关键目标丢失（mIoU下降15%-20%）12	精度恢复至89%以上（对比全计算模型仅减少3%）
能效比	全计算能耗高，静态剪枝无法应急响应13	常态能耗降低50%，突发能耗仅增12%
硬件适配性	依赖GPU通用计算	支持神经形态芯片（如Loihi14），能效比增加3倍
________________________________________
创新性总结
本项目通过进化优化、动态剪枝、脉冲恢复三者的协同设计，系统性解决了传统视觉感知模型在动态环境下面临的三大矛盾：
	固定与自适应的矛盾 → 持续进化学习框架。
	精度与效率的矛盾 → 时空联合剪枝 + 进化策略优化。
	常态与突发的矛盾 → 脉冲式特征按需恢复。
4.1 总体技术路线
1. 基础结构（Vision-Transformer）
Vision Transformer将图像分割为固定大小的图像块（Patches），通过线性映射得到序列化的Token输入：
 
	X_p^i：第i个图像块（Patch）的像素值。
	E：线性投影矩阵，将图像块映射为嵌入向量。
	Epos：位置编码，保留空间位置信息。
	自注意力机制（Self-Attention）
每个Transformer层通过多头自注意力（MSA）建模全局依赖关系：
	Q,K,V：Query、Key、Value矩阵，由输入特征线性变换得到。
	dk：Key向量的维度，用于缩放点积结果。
3. 计算复杂度瓶颈
传统ViT的全局注意力计算复杂度为O(N2)（N为Token数），在处理高分辨率视频时（如1080p输入，N=1920×1080/162=8100），计算量极大，难以满足实时性需求。
 
Model overview. We split an image into fixed-size patches, linearly embed each of them,add position embeddings, and feed the resulting sequence of vectors to a standard Transformer encoder. In order to perform classification, we use the standard approach of adding an extra learnable “classification token” to the sequence.1

   
总体技术路线示意图
4.2 分阶段实施方案
阶段一：动态剪枝模块设计
 
CNN 模型通常利用结构降采样策略来构建层次化架构，如图(a)所示。图(b)中的非结构化和数据依赖的降采样方法可以更好地利用输入数据中的稀疏性。由于自注意力操作的特性，非结构化 Token 集也易于通过并行计算加速。(c)使用L2算法中每个空间位置对最终预测的影响。这些结果表明，视觉 Transformer 中的最终预测仅基于最有信息的 Token 子集，这表明可以移除大量 Token 而不会损害性能。18
任务：实现光流引导的时空剪枝与基础进化策略。
方法： 
1.使用RAFT-Lite轻量光流网络提取运动区域，生成运动掩膜。使用轻量级光流模型（如RAFT-Lite）计算相邻帧光流场 Ft→t−1 。
生成二值运动掩膜 Mt ：
 
2.设计动态剪枝模块，对静态区域降采样，运动区域保留密集计算。
3.引入贡献度得分（L2范数）评估Token重要性，初步实现固定阈值剪枝。
 
验证指标：剪枝后mIoU损失≤2%，FLOPs降低≥30%。
阶段二：进化算法优化
 
Evolution-ViT 的补丁分组图
(a)：有 30个编码个体，每个个体代表一个包含 12个块的 ViT 架构，每个块包含 196个补丁。(b)：根据块的数量，补丁被分为 12 组，每组包含 30个个体，每个个体有 196个维度。19
任务：通过进化算法动态调整剪枝阈值。
方法：
1.基因编码：将各层剪枝率、运动检测阈值编码为基因序列。
         参数向量 θ=(ρhead ,ρtoken ,τ)，其中：
ρhead ：注意力头剪枝率   ρtoken : Token剪枝率   τ : 光流运动阈值
2.适应度函数：
         F(θ)=α⋅mIoU(θ)+β⋅(1−FLOPsbase FLOPs(θ) )
推荐权重： α=0.7, β=0.3
3.使用CMA-ES算法搜索帕累托最优解集。
工具：DEAP库（进化算法框架）、PyTorch Lightning。 
阶段三：类脑脉冲恢复机制
 
用于运动识别的传感器内 SNN
a：事件驱动示意图SNN。像素阵列以及单个像素和输出神经元的对应电路图。b：像素感应过程后的输出光电流 I。只有光强度发生变化的区域才会产生正或负电流尖峰。c：训练后每个子像素阵列的响应度分布。每个子像素阵列在某个区域内具有更强的响应度分布，表明对不同运动的敏感性不同。d：当依次进行左手挥动、右手挥动和手臂旋转时，输出神经元的生成输出尖峰。20
任务：集成脉冲式特征恢复模块。
方法：
1.设计脉冲触发条件：当区域特征梯度突变（如突发物体出现）时激活被剪枝路径。
特征突变检测：
       Dt =||∇Ft −∇Ft−1||2  （当 Dt >γ 时触发恢复）。
2.模拟SNN的膜电位累积机制，控制脉冲发放频率。
硬件适配：在Intel Loihi芯片上测试脉冲计算能效。
阶段四：系统集成与优化
任务：端到端模型训练与部署。
方法：
1.联合训练光流网络与分割模型，减少误差传导。
2.使用TensorRT量化模型，部署至Jetson AGX Xavier边缘设备。
3.在CARLA仿真平台生成极端场景（暴雨、夜间）测试鲁棒性。
5.实验设计与测试
训练集：
Cityscapes Video（街景视频序列）15
真实场景覆盖，训练模型对复杂场景的分类能力，对密集物体的个体分离能力，对静态环境和动态目标的联合分割效果，以及对运动轨迹的预测能力。
DAVIS（Denly-Annotated Video Segmentation）
高质量视频分割数据集，提供逐帧像素级标注，适合测试突发场景（如遮挡、快速运动）的响应能力。
测试集：
CARLA合成数据（模拟遮挡、光照变化）
静态与动态场景测试，开环与闭环评估，对抗鲁棒性评估
对比基线：
传统方法：DeepLabv3+16、PSPNet17。
Transformer模型：Swin- Transformer、Transformer、Vision- Transformer。
动态剪枝方法：Dynamic-ViT、Ada-ViT。


